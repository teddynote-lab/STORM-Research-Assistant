# ğŸŒªï¸ STORM Research Assistant

> **STORM**(Synthesis of Topic Outline through Retrieval and Multi-perspective question asking) ê°œë…ì„ í™œìš©í•œ AI ì—°êµ¬ ë³´ì¡° ì‹œìŠ¤í…œ

## ğŸ“– ì†Œê°œ

STORM Research AssistantëŠ” ë³µì¡í•œ ì£¼ì œì— ëŒ€í•´ ì‹¬ì¸µì ì¸ ì—°êµ¬ ë³´ê³ ì„œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” LangGraph ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ê´€ì ì„ ê°€ì§„ AI ë¶„ì„ê°€ë“¤ì´ ì „ë¬¸ê°€ì™€ ì¸í„°ë·°ë¥¼ ì§„í–‰í•˜ê³ , ì›¹ê³¼ í•™ìˆ  ìë£Œë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¢…í•©ì ì¸ ì—°êµ¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

### ğŸ¯ ì£¼ìš” íŠ¹ì§•

- **ğŸ¤– ë‹¤ì¤‘ ê´€ì  ë¶„ì„**: ë‹¤ì–‘í•œ ë°°ê²½ê³¼ ì „ë¬¸ì„±ì„ ê°€ì§„ AI ë¶„ì„ê°€ë“¤ì´ ì—°êµ¬ì— ì°¸ì—¬
- **ğŸ’¬ ë™ì  ì¸í„°ë·°**: ê° ë¶„ì„ê°€ê°€ ì „ë¬¸ê°€ì™€ ì‹¬ì¸µ ì¸í„°ë·° ì§„í–‰
- **ğŸ” í†µí•© ê²€ìƒ‰**: Tavily(ì›¹ ê²€ìƒ‰)ì™€ ArXiv(í•™ìˆ  ë…¼ë¬¸) ë™ì‹œ í™œìš©
- **ğŸ“Š ë³‘ë ¬ ì²˜ë¦¬**: ì—¬ëŸ¬ ì¸í„°ë·°ë¥¼ ë™ì‹œì— ì§„í–‰í•˜ì—¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- **âœï¸ ìë™ ë³´ê³ ì„œ ìƒì„±**: ì„œë¡ , ë³¸ë¬¸, ê²°ë¡ ì„ í¬í•¨í•œ ì™„ì„±ë„ ë†’ì€ ë³´ê³ ì„œ ì‘ì„±
- **ğŸ”„ ì‚¬ìš©ì í”¼ë“œë°±**: ë¶„ì„ê°€ ìƒì„± ë‹¨ê³„ì—ì„œ ì‚¬ìš©ì ê°œì… ê°€ëŠ¥

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### ì‹œìŠ¤í…œ êµ¬ì¡°

```
ğŸ“ src/storm_research/
â”œâ”€â”€ ğŸ“„ __init__.py          # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ ğŸ§  graph.py            # LangGraph ê·¸ë˜í”„ ì •ì˜ (ë©”ì¸ ë¡œì§)
â”œâ”€â”€ ğŸ“Š state.py            # ìƒíƒœ ë° ë°ì´í„° ëª¨ë¸ ì •ì˜
â”œâ”€â”€ ğŸ’¬ prompts.py          # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”œâ”€â”€ âš™ï¸ configuration.py     # ì‹œìŠ¤í…œ ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ ğŸ”§ tools.py            # ê²€ìƒ‰ ë„êµ¬ êµ¬í˜„
â””â”€â”€ ğŸ› ï¸ utils.py            # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
```

### ì›Œí¬í”Œë¡œìš°

```mermaid
graph TD
    A[ì‹œì‘] --> B[ë¶„ì„ê°€ ìƒì„±]
    B --> C{ì‚¬ìš©ì í”¼ë“œë°±}
    C -->|í”¼ë“œë°± ìˆìŒ| B
    C -->|í”¼ë“œë°± ì—†ìŒ| D[ë³‘ë ¬ ì¸í„°ë·° ì‹œì‘]
    D --> E1[ë¶„ì„ê°€1 ì¸í„°ë·°]
    D --> E2[ë¶„ì„ê°€2 ì¸í„°ë·°]
    D --> E3[ë¶„ì„ê°€3 ì¸í„°ë·°]
    E1 --> F1[ì§ˆë¬¸ ìƒì„±]
    F1 --> G1[ì›¹/ArXiv ê²€ìƒ‰]
    G1 --> H1[ë‹µë³€ ìƒì„±]
    H1 -->|ì¶”ê°€ ì§ˆë¬¸| F1
    H1 -->|ì™„ë£Œ| I1[ì„¹ì…˜ ì‘ì„±]
    I1 --> J[ë³´ê³ ì„œ í†µí•©]
    J --> K[ì„œë¡  ì‘ì„±]
    J --> L[ê²°ë¡  ì‘ì„±]
    K --> M[ìµœì¢… ë³´ê³ ì„œ]
    L --> M
    M --> N[ì¢…ë£Œ]
```

## ğŸš€ ì„¤ì¹˜ ë° ì‹¤í–‰

### 1. í™˜ê²½ ì„¤ì •

```bash
# uvë¥¼ ì‚¬ìš©í•œ í™˜ê²½ ì„¤ì •
uv venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
uv pip install -e .
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”:

```env
# í•„ìˆ˜ API í‚¤
TAVILY_API_KEY=your_tavily_key

# LLM Providerë³„ API í‚¤ (ì‚¬ìš©í•  providerì— ë”°ë¼ ì„¤ì •)
# OpenAI
OPENAI_API_KEY=your_openai_key

# Anthropic
ANTHROPIC_API_KEY=your_anthropic_key

# Azure OpenAI
AZURE_OPENAI_API_KEY=your_azure_openai_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
```

### 3. LangGraph Studio ì‹¤í–‰

```bash
# LangGraph Studio ì„¤ì¹˜ (ì²˜ìŒ í•œ ë²ˆë§Œ)
pip install langgraph-cli

# Studio ì‹¤í–‰
langgraph up
```

## ğŸ“ ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from storm_research import graph
from langchain_core.runnables import RunnableConfig

# ì„¤ì •
config = RunnableConfig(
    configurable={
        "thread_id": "research-001",
        "model": "azure_openai/gpt-4.1",  # ê¸°ë³¸ê°’, ë‹¤ë¥¸ ëª¨ë¸ë„ ì‚¬ìš© ê°€ëŠ¥
        "max_analysts": 3,
        "max_interview_turns": 3,
    }
)

# ì—°êµ¬ ì‹œì‘
inputs = {
    "topic": "LangGraphì˜ ì¥ì ê³¼ ì‹¤ì œ í™œìš© ì‚¬ë¡€",
    "max_analysts": 3
}

# ì‹¤í–‰ (ì²« ë²ˆì§¸ ë‹¨ê³„: ë¶„ì„ê°€ ìƒì„±)
result = await graph.ainvoke(inputs, config)

# ì‚¬ìš©ì í”¼ë“œë°± ì œê³µ (ì„ íƒì )
await graph.aupdate_state(
    config,
    {"human_analyst_feedback": "AI ìœ¤ë¦¬ ì „ë¬¸ê°€ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”"},
    as_node="human_feedback"
)

# ì—°êµ¬ ì™„ë£Œ
final_result = await graph.ainvoke(None, config)
print(final_result["final_report"])
```

### ì„¤ì • ì˜µì…˜

| ì„¤ì • | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|--------|------|
| `model` | `azure/gpt-4.1` | ì‚¬ìš©í•  LLM ëª¨ë¸ (provider/model í˜•ì‹) |
| `max_analysts` | 3 | ìƒì„±í•  ë¶„ì„ê°€ ìˆ˜ |
| `max_interview_turns` | 3 | ì¸í„°ë·° ìµœëŒ€ í„´ ìˆ˜ |
| `tavily_max_results` | 3 | Tavily ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ |
| `arxiv_max_docs` | 3 | ArXiv ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ |
| `parallel_interviews` | `True` | ë³‘ë ¬ ì¸í„°ë·° ì‹¤í–‰ ì—¬ë¶€ |

#### ì§€ì› ëª¨ë¸
- **Azure OpenAI**: `azure/gpt-4.1`, `azure/gpt-4o` ë“±
- **OpenAI**: `openai/gpt-4`, `openai/gpt-4-turbo` ë“±
- **Anthropic**: `anthropic/claude-3-5-sonnet-20240620` ë“±

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
make test

# íŠ¹ì • í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‹¤í–‰
make test TEST_FILE=tests/unit_tests/test_configuration.py

# í†µí•© í…ŒìŠ¤íŠ¸
python -m pytest tests/integration_tests/
```

## ğŸ“š ì˜ˆì œ

### ê¸°ìˆ  ë¦¬ì„œì¹˜
```python
topic = "ì°¨ì„¸ëŒ€ AI ì•„í‚¤í…ì²˜: Transformerë¥¼ ë„˜ì–´ì„œ"
```

### ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„
```python
topic = "2024ë…„ í•œêµ­ ìŠ¤íƒ€íŠ¸ì—… ìƒíƒœê³„ ë¶„ì„ê³¼ íˆ¬ì íŠ¸ë Œë“œ"
```

### í•™ìˆ  ì—°êµ¬
```python
topic = "ì–‘ì ì»´í“¨íŒ…ì´ ì•”í˜¸í™” ê¸°ìˆ ì— ë¯¸ì¹˜ëŠ” ì˜í–¥"
```

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”.

## ğŸ™ ê°ì‚¬ì˜ ë§

- Stanfordì˜ STORM ë…¼ë¬¸ì—ì„œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤
- LangGraph íŒ€ì˜ í›Œë¥­í•œ í”„ë ˆì„ì›Œí¬ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤
- Tavilyì™€ ArXiv APIë¥¼ ì œê³µí•´ì£¼ì‹  íŒ€ë“¤ê»˜ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤

---

**Made with â¤ï¸ using LangGraph**